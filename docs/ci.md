# 持续集成

## 是什么？

如果说频繁的将代码合并到主干上～这时候就很难保证主干的代码的正确性，所以需要在每一次合并代码之前进行测试，但是我每次写完代码以后还要手动去跑测试就比较烦了，这个时候你可能就想要一个你写完代码合并到主干就能自动给你测试的方案，这就是持续集成。

持续集成的好处也非常的明显：

  - 快速发现错误(合并到主干就去测试，测试不过就是这一次的合并有问题)。
  - 防止分支偏离主干太多(每次一小点更新就合并到主干，能够有效的保证分支和主干的代码相差不多)。

基于上面的好处，使用持续集成能够有效的保证代码的高质量，每次迭代的明确性。

## 关于流程

根据持续集成的设计，代码从提交到生产环境，会经历以下的步骤。

### 提交

开发者完成代码的开发后，往代码仓库提交代码。

在`GitHub`中，就是在你`clone`出来的仓库的分支上开发完毕并且发起一次`pull request`后的整个过程。

### 测试

代码仓库对每一次的`commit`操作都配置了钩子，只要提交代码或者合并进主干，就会跑自动化测试。

在`GitHub`中，其实就是上一步后自动执行的过程。

### 构建

在完成测试后，代码就可以合并进主干了，代码算是可以交付了。

在`Github`中，就是原仓库的作者合并了你的代码。

## 项目实践

上面说了一堆关于持续集成的内容，其实也不是必须需要这个东西，它就像一件辅助装备，没有不会不行，有会更好，在`Practice`中使用了持续集成，秉持着本文档要详细的把`Practice`介绍齐全，所以还是说说持续集成在`GitHub`中的操作。

### 服务的选择

这个东西既然已经存在了蛮长的时间了，那服务肯定是不少的～我也没有一一的研究过，所以就不具体的说每一种不同服务的优缺点了～

我选择的时候就是看`GitHub`上大项目一般使用的服务，所以工具就选择的`Travis CI`。

### Travis CI

关于`Travis CI`的使用，网上也是一搜一大堆，我就不多赘述了，直接说本项目是如何使用的，打开项目根目录下的`.travis.yml`文件。

```yaml
language: node_js

node_js:
  - 10

services:
  - mongodb

cache: yarn

env:
  - NODE_ENV=test

script:
  - cd ./packages/server && yarn test

after_success:
  - yarn run coverage
```

里面具体到每一行的意思就是：

  - 指定当前的语言是`node_js`
  - 指定`node`版本为`10`，依赖服务有`mongodb`
  - 模块安装使用缓存策略`cache: yarn`
  - 环境为测试环境，跑测试的命令为`cd ./packages/server && yarn test`
  - 测试都跑成功后执行`yarn run coverage`。

很好理解了吧～唯一可能就是最后那一步，其实是可以省略的，不过我为了多输出一个测试报告，关于测试报告看后面。

### CodeCov

这个玩意儿是个啥呢？就是我们上面说的关于测试报告的东西。他能帮我们展示我们执行测试的结果，网上类似的工具也有很多，选择它的原因同上，没有做仔细的比较，直接选择了比较厉害的开源项目的选择。

他的使用很简单，也有一个配置文件，打开项目根目录下的`.codecov.yml`文件。

```yarml
codecov:
  branch: master
```

你会发现怎么只有一句～哈哈哈哈，这一句也是可有可无的，只是写在这里占个位置，直接使用`Travis CI`将生成的测试报告推送到`CodeCov`就行了～至于如何生成测试报告就不是这一篇里涉及的了～详见测试相关内容。

## 装逼指南

其实讲完上面的内容，本项目关于持续集成的内容也就差不多了～这一节顺便教教大家如何用这玩意儿装逼。

如果你常常逛`GitHub`的话，你会发现大部分厉害的项目它们都有很多小图标，类似`build(passing)`这种，其实就是用上诉类似的工具实现的。

具体实现可以看我的[测试仓库](https://github.com/mintsweet/fe-tools-test)，这个仓库除了持续集成的测试以外还有一些关于代码提交检测之类的测试。

